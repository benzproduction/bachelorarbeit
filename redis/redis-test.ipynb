{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ImportWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from helpers import get_env\n",
    "\n",
    "API_KEY, RESOURCE_ENDPOINT = get_env(\"azure-openai\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2022-12-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 9\n",
      "Number of docs: 698\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from config import TEXT_EMBEDDING_CHUNK_SIZE\n",
    "data_dir = '../data/raw/real_estate_txts'\n",
    "txt_files = sorted([x for x in os.listdir(data_dir) if 'DS_Store' not in x])\n",
    "print(f\"Number of files: {len(txt_files)}\")\n",
    "docs_count = 0\n",
    "for file in txt_files:\n",
    "    with open(os.path.join(data_dir,file), 'r') as f:\n",
    "        docs_count += len(f.readlines()) // TEXT_EMBEDDING_CHUNK_SIZE\n",
    "\n",
    "print(f\"Number of docs: {docs_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import get_redis_connection\n",
    "\n",
    "redis_client = get_redis_connection()\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "keys = redis_client.keys(f\"index_300t_chunks:*\")\n",
    "keys = [key.decode('utf-8') for key in keys]\n",
    "docs = []\n",
    "for key in keys:\n",
    "    element_data = {'id': key}\n",
    "    element_metadata = redis_client.hgetall(key)\n",
    "    for key, value in element_metadata.items():\n",
    "        try:\n",
    "            element_data[key.decode('utf-8')] = value.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            element_data[key.decode('utf-8')] = value.decode('ISO-8859-1')\n",
    "    docs.append(element_data)\n",
    "print(f\"Number of docs: {len(docs)}\")\n",
    "df = pd.DataFrame(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  id page  \\\n",
      "0  index_300t_chunks:Emerging-Trends_USCanada-202...    3   \n",
      "1          index_300t_chunks:isa-outlook-2023.pdf-!6    2   \n",
      "2         index_300t_chunks:isa-outlook-2023.pdf-!63   17   \n",
      "3  index_300t_chunks:2022-09-21_Immobilienmarkt_D...   48   \n",
      "4  index_300t_chunks:outlook-real-estatet-market-...    3   \n",
      "\n",
      "                                            filename  \\\n",
      "0                  Emerging-Trends_USCanada-2023.pdf   \n",
      "1                               isa-outlook-2023.pdf   \n",
      "2                               isa-outlook-2023.pdf   \n",
      "3  2022-09-21_Immobilienmarkt_Deutschland_2022_20...   \n",
      "4   outlook-real-estatet-market-germany-dec-2022.pdf   \n",
      "\n",
      "                                          text_chunk  \\\n",
      "0   No part of this publication may be reproduced...   \n",
      "1   The eerily weird Lang-2525 juxtaposition impl...   \n",
      "2   Supply is projected to increase in major logi...   \n",
      "3   No sharp rent rises likely in spite of tight ...   \n",
      "4   Such an effect could also be observed with re...   \n",
      "\n",
      "                                      content_vector  \n",
      "0  \u0017°»3Ö»\u0001\u0019\u0002¼R#¼¬\u001c'<ÎØ\u001a=ür®¼²®y¼\u0011ô×¼Ï§¼¦F=\u001cm...  \n",
      "1  7\u0011\u0000½Kv¼È¡»À\u000fÒº»\u0007æ»\u001fa2<~²\u0012½¾\u0016½;R\u001eü¼\u001e×¼hÍ;\u0002G...  \n",
      "2  }>:\u0007ï¼s\u000b¼øº¼·±9;×<¬-\u0000½\u0014ðµ»\u001bí×¼ì@é¼\u0005ÑÓ;Èé...  \n",
      "3  ïø\u0017<\u000fß¼Éæ\u0002¼V½t#\u001bº·Ù\u001e<@à\u0010½¶?4;£â¼m]\u000e½J5<}Ð...  \n",
      "4  õs\u000e;P¹\u0000½ÂÕ»V\u0018¼.(á»)äd<8R£¼ñ/¼Uýå»\\\u0016¼<ß...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the content_vector column\n",
    "df.drop(columns=['content_vector'], inplace=True)\n",
    "# save the df to a csv file\n",
    "df.to_csv('index_300t_chunks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'index_400t_chunks', b'index_e5_embeddings', b'index_150t_chunks', b'index_300t_chunks']\n"
     ]
    }
   ],
   "source": [
    "indices = redis_client.execute_command(\"FT._LIST\")\n",
    "print(indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the index exists and has the right number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Index name\n"
     ]
    }
   ],
   "source": [
    "from config import INDEX_NAME\n",
    "# Check if index exists\n",
    "try:\n",
    "    redis_client.ft(INDEX_NAME).info()\n",
    "    print(\"Index already exists\")\n",
    "    print(f\"Number of docs in index: {redis_client.ft(INDEX_NAME).info()['num_docs']}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLETLY FLUSH THE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import get_redis_connection\n",
    "\n",
    "redis_client = get_redis_connection()\n",
    "redis_client.flushdb()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestion\n",
    "\n",
    "Handled in the main.py file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
