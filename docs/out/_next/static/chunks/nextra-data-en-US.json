{"/app":{"title":"Application Overview","data":{"":"general img","features#Features":""}},"/eval":{"title":"System Evaluation","data":{"":"","setup#Setup":"componets\nregistry\neval run","metrics#Metrics":"","results#Results":""}},"/":{"title":"Introduction","data":{"":"This project, developed as part of my bachelor's thesis, aims at creating an intelligent question-answer system for searching and retrieving information in file data spaces. The repository is split into two main parts: the application and the evaluation of the system. The application itself comes in two versions: one built with Streamlit (Python-based), and another built with Next.js. To test the application locally, it's recommended to use the Streamlit version.","getting-started#Getting Started":"Before you can start using the application, there are a few steps you need to follow:","downloading-the-used-documents#Downloading the Used Documents":"Documents can be downloaded by running the Python script found in data/load.py. This will download the PDFs and store them in the data/raw/pdfs directory.","docker-startup#Docker Startup":"The application requires a running Redis Stack on localhost:6379. This can be easily set up by running the following Docker command:\ndocker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest","environment-variables#Environment Variables":"The application requires two environment variables to be set:\nOPENAI_API_KEY: Your OpenAI API key.\nAZURE_OPENAI_ENDPOINT: The endpoint for Azure's OpenAI service.\nThe application was developed using the Azure OpenAI language model Text-Davinci-003. Using the Azure version is not strictly required, but it is recommended as changing to the standard OpenAI API would require modifications to the code in multiple places und may change the evaluation results.","overview-of-the-general-idea#Overview of the General Idea":"The goal of this project was to design and implement a system that can effectively search and retrieve information from a data space made up of files. The challenge was to enable users to intuitively find information without having to know where and how it's stored. The project addresses this challenge by leveraging artificial intelligence technologies, specifically language models and vector databases.The developed system works as follows:\nText Segmentation and Vectorization: A collection of PDF documents is divided into individual text segments, known as \"chunks\". These text chunks are then converted into vectors using an embedding model.\nStorage in Database: The resulting vectors are stored in a Redis database.\nQuery Processing: When a search query is made, the query itself is also converted into a vector and sent to the database.\nSearching for Similar Text Segments: The database performs a k-nearest neighbors (kNN) search and returns the best matching text chunks.\nGeneration of Response: Another language model takes the query and the matching text chunk, and creates a summary in the context of the query. This summary is then presented to the user as a concrete answer.\n\nThe result is an intelligent question-answer system that allows users to search and retrieve information in an intuitive and user-friendly manner."}}}