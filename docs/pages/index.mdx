# Introduction

This project, developed as part of my bachelor's thesis, aims at creating an intelligent question-answer system for searching and retrieving information in file data spaces. The repository is split into two main parts: the application and the evaluation of the system. The application itself comes in two versions: one built with Streamlit (Python-based), and another built with Next.js. To test the application locally, it's recommended to use the Streamlit version.

## Getting Started

Before you can start using the application, there are a few steps you need to follow:

### Downloading the Used Documents

Documents can be downloaded by running the Python script found in `data/load.py`. This will download the PDFs and store them in the `data/raw/pdfs` directory.

### Docker Startup

The application requires a running Redis Stack on `localhost:6379`. This can be easily set up by running the following Docker command:

```bash
docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest
```

### Environment Variables
The application requires two environment variables to be set:

- **`OPENAI_API_KEY`**: Your OpenAI API key.
- **`AZURE_OPENAI_ENDPOINT`**: The endpoint for Azure's OpenAI service.

The application was developed using the Azure OpenAI language model Text-Davinci-003. Using the Azure version is not strictly required, but it is recommended as changing to the standard OpenAI API would require modifications to the code in multiple places und may change the evaluation results.

## Overview of the General Idea

The goal of this project was to design and implement a system that can effectively search and retrieve information from a data space made up of files. The challenge was to enable users to intuitively find information without having to know where and how it's stored. The project addresses this challenge by leveraging artificial intelligence technologies, specifically language models and vector databases.

The developed system works as follows:

1. **Text Segmentation and Vectorization**: A collection of PDF documents is divided into individual text segments, known as "chunks". These text chunks are then converted into vectors using an embedding model.

2. **Storage in Database**: The resulting vectors are stored in a Redis database.

3. **Query Processing**: When a search query is made, the query itself is also converted into a vector and sent to the database.

4. **Searching for Similar Text Segments**: The database performs a k-nearest neighbors (kNN) search and returns the best matching text chunks.

5. **Generation of Response**: The language model then takes the query (question) and the matching text chunks, and creates a summary in the context of the query. This summary is then presented to the user as a concrete answer.

The result is an intelligent question-answer system that allows users to search and retrieve information in an intuitive and user-friendly manner.
